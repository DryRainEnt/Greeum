#!/usr/bin/env python3
"""
Create legacy v2.5.2 database for testing AI-powered migration
"""

import sqlite3
import json
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
import random

def create_legacy_database(db_path: str):
    """Create v2.5.2 legacy database with test data"""
    
    # Remove existing file
    Path(db_path).unlink(missing_ok=True)
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Create v2.5.2 legacy schema (WITHOUT actant columns)
    cursor.execute('''
        CREATE TABLE blocks (
            block_index INTEGER PRIMARY KEY,
            timestamp TEXT NOT NULL,
            context TEXT NOT NULL,
            importance REAL NOT NULL,
            hash TEXT NOT NULL,
            prev_hash TEXT NOT NULL
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE block_embeddings (
            block_index INTEGER PRIMARY KEY,
            embedding BLOB,
            FOREIGN KEY (block_index) REFERENCES blocks (block_index)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE block_metadata (
            block_index INTEGER PRIMARY KEY,
            keywords TEXT,
            tags TEXT,
            metadata TEXT,
            FOREIGN KEY (block_index) REFERENCES blocks (block_index)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE block_keywords (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            block_index INTEGER,
            keyword TEXT,
            FOREIGN KEY (block_index) REFERENCES blocks (block_index)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE block_tags (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            block_index INTEGER,
            tag TEXT,
            FOREIGN KEY (block_index) REFERENCES blocks (block_index)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE short_term_memories (
            id TEXT PRIMARY KEY,
            content TEXT NOT NULL,
            importance REAL NOT NULL,
            created_at TEXT NOT NULL,
            expires_at TEXT,
            ttl_seconds INTEGER
        )
    ''')
    
    # Insert test data - diverse memory contexts for testing AI parsing
    test_memories = [
        {
            "context": "ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤",
            "importance": 0.8,
            "keywords": ["ì‚¬ìš©ì", "ê¸°ëŠ¥", "ìš”ì²­"],
            "tags": ["feature_request", "user_feedback"]
        },
        {
            "context": "Claudeê°€ v2.5.2 ë²„ê·¸ë¥¼ ë°œê²¬í•˜ê³  ìˆ˜ì • ë°©ë²•ì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤",
            "importance": 0.9,
            "keywords": ["Claude", "ë²„ê·¸", "ìˆ˜ì •"],
            "tags": ["bug_fix", "ai_assistance"]
        },
        {
            "context": "ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ë°±ì—…ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤",
            "importance": 0.6,
            "keywords": ["ì‹œìŠ¤í…œ", "ë°±ì—…", "ìë™"],
            "tags": ["system", "backup", "automatic"]
        },
        {
            "context": "ê°œë°œíŒ€ì´ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íšì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤",
            "importance": 0.85,
            "keywords": ["ê°œë°œíŒ€", "ë§ˆì´ê·¸ë ˆì´ì…˜", "ê³„íš"],
            "tags": ["development", "migration", "planning"]
        },
        {
            "context": "í…ŒìŠ¤íŠ¸ ê²°ê³¼ 98.9% ì„±ê³µë¥ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤",
            "importance": 0.7,
            "keywords": ["í…ŒìŠ¤íŠ¸", "ì„±ê³µë¥ ", "ê²°ê³¼"],
            "tags": ["testing", "performance", "success"]
        },
        {
            "context": "ì•¡íƒ„íŠ¸ ëª¨ë¸ êµ¬í˜„ì„ ìœ„í•œ ì„¤ê³„ ë¬¸ì„œê°€ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "importance": 0.9,
            "keywords": ["ì•¡íƒ„íŠ¸", "ëª¨ë¸", "ì„¤ê³„"],
            "tags": ["actant_model", "design", "documentation"]
        },
        {
            "context": "ì¸ê³¼ê´€ê³„ ë¶„ì„ ì—”ì§„ ê°œë°œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "importance": 0.95,
            "keywords": ["ì¸ê³¼ê´€ê³„", "ë¶„ì„", "ì—”ì§„"],
            "tags": ["causality", "analysis", "engine"]
        },
        {
            "context": "ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì„±ëŠ¥ì´ 5ë°° í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤",
            "importance": 0.8,
            "keywords": ["ë©”ëª¨ë¦¬", "ê²€ìƒ‰", "ì„±ëŠ¥"],
            "tags": ["memory", "search", "performance"]
        },
        {
            "context": "AI íŒŒì„œ ì •í™•ë„ í…ŒìŠ¤íŠ¸ì—ì„œ 87% ì„±ê³µë¥  ë‹¬ì„±",
            "importance": 0.75,
            "keywords": ["AI", "íŒŒì„œ", "ì •í™•ë„"],
            "tags": ["ai_parser", "accuracy", "testing"]
        },
        {
            "context": "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ v2.5.3 ì—…ê·¸ë ˆì´ë“œ ì¤€ë¹„ ì™„ë£Œ",
            "importance": 0.9,
            "keywords": ["ë°ì´í„°ë² ì´ìŠ¤", "ìŠ¤í‚¤ë§ˆ", "ì—…ê·¸ë ˆì´ë“œ"],
            "tags": ["database", "schema", "upgrade"]
        }
    ]
    
    prev_hash = ""
    
    for i, memory_data in enumerate(test_memories):
        timestamp = (datetime.now() - timedelta(days=10-i)).isoformat()
        
        # Create block hash
        block_data = {
            'block_index': i,
            'timestamp': timestamp,
            'context': memory_data['context'],
            'prev_hash': prev_hash
        }
        
        block_hash = hashlib.sha256(str(block_data).encode()).hexdigest()[:16]
        
        # Insert block
        cursor.execute('''
            INSERT INTO blocks (block_index, timestamp, context, importance, hash, prev_hash)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (i, timestamp, memory_data['context'], memory_data['importance'], block_hash, prev_hash))
        
        # Insert keywords
        for keyword in memory_data['keywords']:
            cursor.execute('''
                INSERT INTO block_keywords (block_index, keyword)
                VALUES (?, ?)
            ''', (i, keyword))
        
        # Insert tags
        for tag in memory_data['tags']:
            cursor.execute('''
                INSERT INTO block_tags (block_index, tag)
                VALUES (?, ?)
            ''', (i, tag))
        
        # Insert metadata
        metadata = {
            "keywords": memory_data['keywords'],
            "tags": memory_data['tags'],
            "test_data": True
        }
        cursor.execute('''
            INSERT INTO block_metadata (block_index, keywords, tags, metadata)
            VALUES (?, ?, ?, ?)
        ''', (i, json.dumps(memory_data['keywords']), json.dumps(memory_data['tags']), json.dumps(metadata)))
        
        prev_hash = block_hash
    
    # Create indexes
    cursor.execute('CREATE INDEX idx_blocks_timestamp ON blocks(timestamp)')
    cursor.execute('CREATE INDEX idx_block_keywords_keyword ON block_keywords(keyword)')
    cursor.execute('CREATE INDEX idx_block_tags_tag ON block_tags(tag)')
    
    conn.commit()
    conn.close()
    
    print(f"âœ… Legacy v2.5.2 database created: {db_path}")
    print(f"ğŸ“Š {len(test_memories)} test memory blocks inserted")
    print("ğŸ¯ Ready for AI-powered migration testing!")

if __name__ == "__main__":
    db_path = Path(__file__).parent / "data" / "memory.db"
    db_path.parent.mkdir(exist_ok=True)
    
    create_legacy_database(str(db_path))
    
    print("\n" + "="*50)
    print("ğŸ§ª Test Database Summary")
    print("="*50)
    
    # Verify creation
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM blocks")
    block_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM block_keywords")
    keyword_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM block_tags")
    tag_count = cursor.fetchone()[0]
    
    print(f"ğŸ“Š Blocks: {block_count}")
    print(f"ğŸ·ï¸  Keywords: {keyword_count}")
    print(f"ğŸ”– Tags: {tag_count}")
    
    # Show sample data
    print("\nğŸ“ Sample Memory Contexts:")
    cursor.execute("SELECT block_index, LEFT(context, 80) FROM blocks LIMIT 3")
    for idx, context in cursor.fetchall():
        print(f"  {idx}: {context}...")
    
    conn.close()
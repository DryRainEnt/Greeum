#!/usr/bin/env python3
"""
Greeum v2.0.4 ì¼ê°„ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸
- í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ ì¸¡ì •
- ì¼ê´€ëœ ì„±ëŠ¥ ê¸°ì¤€ ìœ ì§€
- ì„±ëŠ¥ regression ê°ì§€
"""

import time
import psutil
import gc
import json
import sys
from datetime import datetime
from pathlib import Path
from contextlib import contextmanager
from typing import Dict, List, Any

# Greeum ëª¨ë“ˆ import
sys.path.insert(0, str(Path(__file__).parent.parent))
from greeum.core.database_manager import DatabaseManager
from greeum.core.block_manager import BlockManager
from greeum.text_utils import process_user_input
from greeum.embedding_models import get_embedding


class DailyBenchmark:
    """ì¼ê°„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "version": "2.0.4",
            "platform": sys.platform,
            "python_version": sys.version,
            "metrics": {}
        }
        
        # í…ŒìŠ¤íŠ¸ìš© ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤
        self.test_db_path = Path.home() / ".greeum_benchmark"
        self.test_db_path.mkdir(exist_ok=True)
        
        self.db_manager = DatabaseManager(str(self.test_db_path / "test.db"))
        self.block_manager = BlockManager(self.db_manager)
        
    @contextmanager
    def measure_time_and_memory(self, operation_name: str):
        """ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì»¨í…ìŠ¤íŠ¸"""
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        gc.collect()
        
        # ì‹œì‘ ìƒíƒœ ì¸¡ì •
        process = psutil.Process()
        start_time = time.perf_counter()
        start_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        try:
            yield
        finally:
            # ì¢…ë£Œ ìƒíƒœ ì¸¡ì •
            end_time = time.perf_counter()
            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # ê²°ê³¼ ì €ì¥
            self.results["metrics"][operation_name] = {
                "duration_ms": round((end_time - start_time) * 1000, 2),
                "memory_delta_mb": round(end_memory - start_memory, 2),
                "peak_memory_mb": round(end_memory, 2)
            }
            
            print(f"âœ… {operation_name}: {self.results['metrics'][operation_name]['duration_ms']}ms")
    
    def benchmark_memory_add_single(self):
        """ë‹¨ì¼ ë©”ëª¨ë¦¬ ì¶”ê°€ ì„±ëŠ¥"""
        test_content = "ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ìš© ë©”ëª¨ë¦¬ ë¸”ë¡ì…ë‹ˆë‹¤. í•œê¸€ê³¼ ì˜ì–´ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        with self.measure_time_and_memory("memory_add_single"):
            result = process_user_input(test_content)
            block_data = {
                "block_index": 0,
                "timestamp": datetime.now().isoformat(),
                "context": test_content,
                "keywords": result.get("keywords", []),
                "tags": result.get("tags", []),
                "embedding": result.get("embedding", []),
                "importance": 0.5,
                "hash": "test_hash",
                "prev_hash": ""
            }
            self.db_manager.add_block(block_data)
    
    def benchmark_memory_add_batch(self, count: int = 100):
        """ë°°ì¹˜ ë©”ëª¨ë¦¬ ì¶”ê°€ ì„±ëŠ¥"""
        test_contents = [
            f"ë°°ì¹˜ í…ŒìŠ¤íŠ¸ {i}ë²ˆì§¸ ë©”ëª¨ë¦¬ ë¸”ë¡ì…ë‹ˆë‹¤. ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…ë‹ˆë‹¤."
            for i in range(count)
        ]
        
        with self.measure_time_and_memory(f"memory_add_batch_{count}"):
            for i, content in enumerate(test_contents):
                result = process_user_input(content)
                block_data = {
                    "block_index": i + 1,
                    "timestamp": datetime.now().isoformat(),
                    "context": content,
                    "keywords": result.get("keywords", []),
                    "tags": result.get("tags", []),
                    "embedding": result.get("embedding", []),
                    "importance": 0.5,
                    "hash": f"test_hash_{i}",
                    "prev_hash": f"test_hash_{i-1}" if i > 0 else ""
                }
                self.db_manager.add_block(block_data)
    
    def benchmark_memory_search_keyword(self):
        """í‚¤ì›Œë“œ ê²€ìƒ‰ ì„±ëŠ¥"""
        keywords = ["í…ŒìŠ¤íŠ¸", "ì„±ëŠ¥", "ë²¤ì¹˜ë§ˆí¬"]
        
        with self.measure_time_and_memory("memory_search_keyword"):
            results = self.db_manager.search_blocks_by_keyword(keywords, limit=10)
            # ê²°ê³¼ ê²€ì¦
            assert isinstance(results, list), "ê²€ìƒ‰ ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤"
    
    def benchmark_memory_search_embedding(self):
        """ì„ë² ë”© ê²€ìƒ‰ ì„±ëŠ¥"""
        query = "ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë‚´ìš©"
        
        with self.measure_time_and_memory("memory_search_embedding"):
            try:
                embedding = get_embedding(query)
                results = self.db_manager.search_blocks_by_embedding(embedding, top_k=10)
                assert isinstance(results, list), "ì„ë² ë”© ê²€ìƒ‰ ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤"
            except Exception as e:
                print(f"âš ï¸  ì„ë² ë”© ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                self.results["metrics"]["memory_search_embedding"] = {
                    "duration_ms": 0,
                    "memory_delta_mb": 0,
                    "peak_memory_mb": 0,
                    "error": str(e)
                }
    
    def benchmark_text_processing(self):
        """í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„±ëŠ¥"""
        test_texts = [
            "í•œê¸€ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ ì¶”ì¶œê³¼ ì„ë² ë”© ìƒì„±ì´ í¬í•¨ë©ë‹ˆë‹¤.",
            "English text processing performance measurement including keyword extraction and embedding generation.",
            "æ··åˆè¯­è¨€æ–‡æœ¬å¤„ç†æ€§èƒ½æµ‹è¯•ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€í•œê¸€ã€Englishçš„å¤„ç†èƒ½åŠ›æµ‹è¯•ã€‚",
            "ğŸ¯ ì´ëª¨ì§€ì™€ íŠ¹ìˆ˜ë¬¸ì @#$% ì²˜ë¦¬ ì„±ëŠ¥ë„ í•¨ê»˜ ì¸¡ì •í•©ë‹ˆë‹¤! (í…ŒìŠ¤íŠ¸ìš©)",
            "Very long text content for performance testing. " * 100  # ê¸´ í…ìŠ¤íŠ¸
        ]
        
        with self.measure_time_and_memory("text_processing_batch"):
            for text in test_texts:
                result = process_user_input(text)
                assert "keywords" in result, "í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨"
                assert "embedding" in result, "ì„ë² ë”© ìƒì„± ì‹¤íŒ¨"
    
    def benchmark_database_operations(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë³¸ ì—°ì‚° ì„±ëŠ¥"""
        # ë¸”ë¡ ì¶”ê°€
        with self.measure_time_and_memory("db_block_insert"):
            for i in range(50):
                block_data = {
                    "block_index": i + 200,
                    "timestamp": datetime.now().isoformat(),
                    "context": f"DB ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¸”ë¡ {i}",
                    "keywords": ["DB", "í…ŒìŠ¤íŠ¸"],
                    "tags": ["ì„±ëŠ¥"],
                    "embedding": [0.1] * 128,
                    "importance": 0.5,
                    "hash": f"db_test_{i}",
                    "prev_hash": f"db_test_{i-1}" if i > 0 else ""
                }
                self.db_manager.add_block(block_data)
        
        # ë¸”ë¡ ì¡°íšŒ
        with self.measure_time_and_memory("db_block_retrieve"):
            for i in range(10):
                block = self.db_manager.get_block(i + 200)
                assert block is not None or i >= 200, f"ë¸”ë¡ {i+200} ì¡°íšŒ ì‹¤íŒ¨"
        
        # ë§ˆì§€ë§‰ ë¸”ë¡ ì •ë³´ ì¡°íšŒ
        with self.measure_time_and_memory("db_last_block_info"):
            for _ in range(20):
                last_info = self.db_manager.get_last_block_info()
                assert last_info is not None, "ë§ˆì§€ë§‰ ë¸”ë¡ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨"
    
    def benchmark_concurrent_simulation(self):
        """ë™ì‹œ ì ‘ê·¼ ì‹œë®¬ë ˆì´ì…˜ (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)"""
        import threading
        import queue
        
        results_queue = queue.Queue()
        errors_queue = queue.Queue()
        
        def worker(worker_id: int):
            """ì›Œì»¤ ìŠ¤ë ˆë“œ í•¨ìˆ˜"""
            try:
                for i in range(10):
                    # ë©”ëª¨ë¦¬ ì¶”ê°€
                    content = f"ë™ì‹œì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì›Œì»¤{worker_id} ì‘ì—…{i}"
                    result = process_user_input(content)
                    
                    # ì§§ì€ ëŒ€ê¸° (ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜)
                    time.sleep(0.01)
                    
                results_queue.put(f"worker_{worker_id}_completed")
            except Exception as e:
                errors_queue.put(f"worker_{worker_id}_error: {e}")
        
        with self.measure_time_and_memory("concurrent_simulation"):
            threads = []
            worker_count = 5
            
            # ìŠ¤ë ˆë“œ ì‹œì‘
            for i in range(worker_count):
                thread = threading.Thread(target=worker, args=(i,))
                threads.append(thread)
                thread.start()
            
            # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
            for thread in threads:
                thread.join(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            
            # ê²°ê³¼ ê²€ì¦
            completed_workers = []
            while not results_queue.empty():
                completed_workers.append(results_queue.get())
            
            errors = []
            while not errors_queue.empty():
                errors.append(errors_queue.get())
            
            print(f"   ì™„ë£Œëœ ì›Œì»¤: {len(completed_workers)}/{worker_count}")
            if errors:
                print(f"   ì˜¤ë¥˜: {errors}")
    
    def calculate_performance_score(self) -> float:
        """ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (0-100)"""
        metrics = self.results["metrics"]
        score = 100.0
        
        # ê° ì§€í‘œë³„ ê°€ì¤‘ì¹˜ ë° ê¸°ì¤€ê°’
        benchmarks = {
            "memory_add_single": {"weight": 0.2, "target_ms": 50, "penalty_per_ms": 0.5},
            "memory_add_batch_100": {"weight": 0.3, "target_ms": 3000, "penalty_per_ms": 0.01},
            "memory_search_keyword": {"weight": 0.15, "target_ms": 100, "penalty_per_ms": 0.3},
            "memory_search_embedding": {"weight": 0.15, "target_ms": 200, "penalty_per_ms": 0.2},
            "text_processing_batch": {"weight": 0.1, "target_ms": 500, "penalty_per_ms": 0.1},
            "concurrent_simulation": {"weight": 0.1, "target_ms": 2000, "penalty_per_ms": 0.05}
        }
        
        for metric_name, benchmark in benchmarks.items():
            if metric_name in metrics and "duration_ms" in metrics[metric_name]:
                duration = metrics[metric_name]["duration_ms"]
                target = benchmark["target_ms"]
                
                if duration > target:
                    # ëª©í‘œì¹˜ë¥¼ ì´ˆê³¼í•œ ê²½ìš° ê°ì 
                    penalty = (duration - target) * benchmark["penalty_per_ms"] * benchmark["weight"]
                    score -= penalty
                else:
                    # ëª©í‘œì¹˜ë³´ë‹¤ ë¹ ë¥¸ ê²½ìš° ë³´ë„ˆìŠ¤
                    bonus = (target - duration) / target * 10 * benchmark["weight"]
                    score += bonus
        
        return max(0, min(100, score))
    
    def generate_recommendations(self) -> List[str]:
        """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        metrics = self.results["metrics"]
        
        # ë©”ëª¨ë¦¬ ì¶”ê°€ ì„±ëŠ¥ ê²€ì‚¬
        if "memory_add_single" in metrics:
            duration = metrics["memory_add_single"]["duration_ms"]
            if duration > 100:
                recommendations.append(f"ë‹¨ì¼ ë©”ëª¨ë¦¬ ì¶”ê°€ê°€ {duration}msë¡œ ëŠë¦¼. í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìµœì í™” ê²€í†  í•„ìš”")
        
        # ê²€ìƒ‰ ì„±ëŠ¥ ê²€ì‚¬
        if "memory_search_keyword" in metrics:
            duration = metrics["memory_search_keyword"]["duration_ms"]
            if duration > 200:
                recommendations.append(f"í‚¤ì›Œë“œ ê²€ìƒ‰ì´ {duration}msë¡œ ëŠë¦¼. ì¸ë±ìŠ¤ ìµœì í™” ê²€í†  í•„ìš”")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²€ì‚¬
        peak_memories = [m.get("peak_memory_mb", 0) for m in metrics.values() if isinstance(m, dict)]
        if peak_memories and max(peak_memories) > 100:
            recommendations.append(f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ {max(peak_memories):.1f}MB. ë©”ëª¨ë¦¬ ìµœì í™” ê²€í†  í•„ìš”")
        
        # ì—ëŸ¬ ê²€ì‚¬
        error_metrics = [name for name, data in metrics.items() 
                        if isinstance(data, dict) and "error" in data]
        if error_metrics:
            recommendations.append(f"ì˜¤ë¥˜ ë°œìƒ ì§€í‘œ: {', '.join(error_metrics)}. ì•ˆì •ì„± ê²€í†  í•„ìš”")
        
        if not recommendations:
            recommendations.append("ëª¨ë“  ì„±ëŠ¥ ì§€í‘œê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ ìœ ì§€ ê¶Œì¥")
        
        return recommendations
    
    def run_all_benchmarks(self):
        """ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("ğŸš€ Greeum v2.0.4 Daily Benchmark ì‹œì‘")
        print(f"   ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   í”Œë«í¼: {sys.platform}")
        print(f"   Python: {sys.version.split()[0]}")
        print()
        
        try:
            # ê°œë³„ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
            self.benchmark_memory_add_single()
            self.benchmark_memory_add_batch(100)
            self.benchmark_memory_search_keyword()
            self.benchmark_memory_search_embedding()
            self.benchmark_text_processing()
            self.benchmark_database_operations()
            self.benchmark_concurrent_simulation()
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            score = self.calculate_performance_score()
            self.results["performance_score"] = round(score, 1)
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self.generate_recommendations()
            self.results["recommendations"] = recommendations
            
            print()
            print(f"ğŸ“Š ì¢…í•© ì„±ëŠ¥ ì ìˆ˜: {score:.1f}/100")
            print("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in recommendations:
                print(f"   - {rec}")
            
        except Exception as e:
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            self.results["error"] = str(e)
        
        finally:
            # ê²°ê³¼ ì €ì¥
            self.save_results()
            
            # ì •ë¦¬
            self.cleanup()
    
    def save_results(self):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        results_dir = Path(__file__).parent.parent / "benchmark_results"
        results_dir.mkdir(exist_ok=True)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ íŒŒì¼ëª…
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = results_dir / f"daily_benchmark_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {results_file}")
        
        # ìµœì‹  ê²°ê³¼ë„ ë³„ë„ ì €ì¥ (ëŒ€ì‹œë³´ë“œìš©)
        latest_file = results_dir / "latest_benchmark.json"
        with open(latest_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
    
    def cleanup(self):
        """í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬"""
        try:
            import shutil
            if self.test_db_path.exists():
                shutil.rmtree(self.test_db_path)
        except Exception as e:
            print(f"âš ï¸  ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    benchmark = DailyBenchmark()
    benchmark.run_all_benchmarks()


if __name__ == "__main__":
    main()
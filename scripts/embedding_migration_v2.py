#!/usr/bin/env python3
"""
ì„ë² ë”© ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ v2.0
SimpleEmbeddingModel â†’ SentenceTransformer ì•ˆì „ ë§ˆì´ê·¸ë ˆì´ì…˜

Features:
- ì•ˆì „í•œ ë°±ì—… ë° ë¡¤ë°±
- ë°°ì¹˜ ì²˜ë¦¬ ë° ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
- ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ í†µí•©
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬

Usage:
    python scripts/embedding_migration_v2.py [options]
    
Options:
    --db-path PATH          ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
    --backup-path PATH      ë°±ì—… ê²½ë¡œ (ê¸°ë³¸: db_path.backup)
    --batch-size N          ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 100)
    --dry-run              ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜
    --verify-only          ê²€ì¦ë§Œ ìˆ˜í–‰
    --rollback             ë°±ì—…ì—ì„œ ë¡¤ë°±
    --force                ê°•ì œ ì‹¤í–‰ (í™•ì¸ ì—†ì´)
"""

import sys
import os
import time
import argparse
import sqlite3
import shutil
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import numpy as np

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from greeum.core.database_manager import DatabaseManager
from greeum.embedding_models import (
    init_sentence_transformer, 
    embedding_registry,
    SimpleEmbeddingModel,
    SentenceTransformerModel
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('embedding_migration.log')
    ]
)
logger = logging.getLogger(__name__)


class EmbeddingMigrator:
    """ì„ë² ë”© ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬ì"""
    
    def __init__(self, db_path: str, backup_path: Optional[str] = None):
        self.db_path = Path(db_path)
        self.backup_path = Path(backup_path) if backup_path else self.db_path.with_suffix('.backup')
        self.migration_log_path = self.db_path.with_suffix('.migration.json')
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ
        self.migration_state = {
            'started_at': None,
            'completed_at': None,
            'total_blocks': 0,
            'migrated_blocks': 0,
            'failed_blocks': 0,
            'errors': [],
            'backup_created': False,
            'rollback_available': False
        }
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.old_model = SimpleEmbeddingModel(dimension=768)
        self.new_model = None
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.db_manager = None
        
    def initialize(self) -> bool:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ˆê¸°í™”"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            self.db_manager = DatabaseManager(connection_string=str(self.db_path))
            
            # Sentence-Transformers ëª¨ë¸ ì´ˆê¸°í™”
            try:
                self.new_model = init_sentence_transformer()
                logger.info("âœ… Sentence-Transformers ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
            except ImportError:
                logger.error("âŒ Sentence-Transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install sentence-transformers")
                return False
            except Exception as e:
                logger.error(f"âŒ Sentence-Transformers ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                return False
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ë¡œë“œ
            self._load_migration_state()
            
            logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _load_migration_state(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ë¡œë“œ"""
        if self.migration_log_path.exists():
            try:
                with open(self.migration_log_path, 'r', encoding='utf-8') as f:
                    self.migration_state = json.load(f)
                logger.info("ğŸ“„ ê¸°ì¡´ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ë¡œë“œë¨")
            except Exception as e:
                logger.warning(f"âš ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_migration_state(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ì €ì¥"""
        try:
            with open(self.migration_log_path, 'w', encoding='utf-8') as f:
                json.dump(self.migration_state, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def create_backup(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ìƒì„±"""
        try:
            if self.backup_path.exists():
                logger.warning(f"âš ï¸ ë°±ì—… íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {self.backup_path}")
                response = input("ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                if response.lower() != 'y':
                    return False
            
            logger.info(f"ğŸ“¦ ë°±ì—… ìƒì„± ì¤‘: {self.db_path} â†’ {self.backup_path}")
            shutil.copy2(self.db_path, self.backup_path)
            
            self.migration_state['backup_created'] = True
            self.migration_state['rollback_available'] = True
            self._save_migration_state()
            
            logger.info("âœ… ë°±ì—… ìƒì„± ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def rollback(self) -> bool:
        """ë°±ì—…ì—ì„œ ë¡¤ë°±"""
        try:
            if not self.backup_path.exists():
                logger.error("âŒ ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return False
            
            if not self.migration_state.get('rollback_available', False):
                logger.error("âŒ ë¡¤ë°±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                return False
            
            logger.info(f"ğŸ”„ ë¡¤ë°± ì¤‘: {self.backup_path} â†’ {self.db_path}")
            shutil.copy2(self.backup_path, self.db_path)
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            self.migration_state = {
                'started_at': None,
                'completed_at': None,
                'total_blocks': 0,
                'migrated_blocks': 0,
                'failed_blocks': 0,
                'errors': [],
                'backup_created': True,
                'rollback_available': True
            }
            self._save_migration_state()
            
            logger.info("âœ… ë¡¤ë°± ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë¡¤ë°± ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_migration_scope(self) -> Dict[str, Any]:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë²”ìœ„ ë¶„ì„"""
        try:
            cursor = self.db_manager.connection.cursor()
            
            # ì „ì²´ ë¸”ë¡ ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM blocks")
            total_blocks = cursor.fetchone()[0]
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ ë¸”ë¡ ìˆ˜
            cursor.execute("""
                SELECT COUNT(*)
                FROM blocks b
                LEFT JOIN block_embeddings e ON b.block_index = e.block_index
                WHERE (e.embedding_model IN ('simple_hash_768', 'default', 'simple', 'simple_768')
                       OR e.embedding_model IS NULL
                       OR e.embedding_model NOT LIKE 'st_%')
            """)
            blocks_to_migrate = cursor.fetchone()[0]
            
            # ì´ë¯¸ ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë¸”ë¡ ìˆ˜
            cursor.execute("""
                SELECT COUNT(*)
                FROM blocks b
                LEFT JOIN block_embeddings e ON b.block_index = e.block_index
                WHERE e.embedding_model LIKE 'st_%'
            """)
            already_migrated = cursor.fetchone()[0]
            
            analysis = {
                'total_blocks': total_blocks,
                'blocks_to_migrate': blocks_to_migrate,
                'already_migrated': already_migrated,
                'migration_percentage': (blocks_to_migrate / total_blocks * 100) if total_blocks > 0 else 0
            }
            
            logger.info(f"ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶„ì„ ê²°ê³¼:")
            logger.info(f"   ì „ì²´ ë¸”ë¡: {total_blocks:,}")
            logger.info(f"   ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ: {blocks_to_migrate:,}")
            logger.info(f"   ì´ë¯¸ ë§ˆì´ê·¸ë ˆì´ì…˜ë¨: {already_migrated:,}")
            logger.info(f"   ë§ˆì´ê·¸ë ˆì´ì…˜ ë¹„ìœ¨: {analysis['migration_percentage']:.1f}%")
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë²”ìœ„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_blocks_to_migrate(self, limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ ë¸”ë¡ ì¡°íšŒ"""
        try:
            cursor = self.db_manager.connection.cursor()
            cursor.execute("""
                SELECT b.block_index, b.context, b.keywords, b.tags, b.importance,
                       e.embedding_model, e.embedding_dim, e.embedding
                FROM blocks b
                LEFT JOIN block_embeddings e ON b.block_index = e.block_index
                WHERE (e.embedding_model IN ('simple_hash_768', 'default', 'simple', 'simple_768')
                       OR e.embedding_model IS NULL
                       OR e.embedding_model NOT LIKE 'st_%')
                ORDER BY b.block_index
                LIMIT ? OFFSET ?
            """, (limit, offset))
            
            columns = [desc[0] for desc in cursor.description]
            blocks = []
            
            for row in cursor.fetchall():
                block = dict(zip(columns, row))
                # embeddingì„ numpy ë°°ì—´ë¡œ ë³€í™˜
                if block['embedding']:
                    try:
                        block['embedding'] = np.frombuffer(block['embedding'], dtype=np.float32).tolist()
                    except:
                        block['embedding'] = None
                blocks.append(block)
            
            return blocks
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ ë¸”ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def migrate_blocks(self, blocks: List[Dict[str, Any]]) -> Tuple[int, int]:
        """ë¸”ë¡ ë°°ì¹˜ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        migrated = 0
        failed = 0
        
        for block in blocks:
            try:
                # ìƒˆ ì„ë² ë”© ìƒì„±
                new_embedding = self.new_model.encode(block['context'])
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
                cursor = self.db_manager.connection.cursor()
                
                # ê¸°ì¡´ ì„ë² ë”© ì •ë³´ ì‚­ì œ
                cursor.execute("DELETE FROM block_embeddings WHERE block_index = ?", (block['block_index'],))
                
                # ìƒˆ ì„ë² ë”© ì •ë³´ ì‚½ì…
                embedding_bytes = np.array(new_embedding, dtype=np.float32).tobytes()
                cursor.execute("""
                    INSERT INTO block_embeddings 
                    (block_index, embedding, embedding_model, embedding_dim, created_at)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    block['block_index'],
                    embedding_bytes,
                    self.new_model.get_model_name(),
                    self.new_model.get_dimension(),
                    datetime.now().isoformat()
                ))
                
                self.db_manager.connection.commit()
                migrated += 1
                
                if migrated % 10 == 0:
                    logger.info(f"ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì§„í–‰: {migrated}/{len(blocks)}")
                
            except Exception as e:
                logger.error(f"âŒ ë¸”ë¡ {block['block_index']} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
                self.migration_state['errors'].append({
                    'block_index': block['block_index'],
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
                failed += 1
        
        return migrated, failed
    
    def run_migration(self, batch_size: int = 100, dry_run: bool = False) -> bool:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        try:
            # ë¶„ì„
            analysis = self.analyze_migration_scope()
            if not analysis:
                return False
            
            if analysis['blocks_to_migrate'] == 0:
                logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            if dry_run:
                logger.info("ğŸ” ë“œë¼ì´ëŸ° ëª¨ë“œ: ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return True
            
            # ë°±ì—… ìƒì„±
            if not self.migration_state.get('backup_created', False):
                if not self.create_backup():
                    return False
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘
            self.migration_state['started_at'] = datetime.now().isoformat()
            self.migration_state['total_blocks'] = analysis['blocks_to_migrate']
            
            logger.info(f"ğŸš€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘: {analysis['blocks_to_migrate']:,}ê°œ ë¸”ë¡")
            
            offset = 0
            total_migrated = 0
            total_failed = 0
            
            while True:
                # ë°°ì¹˜ ì¡°íšŒ
                blocks = self.get_blocks_to_migrate(batch_size, offset)
                if not blocks:
                    break
                
                # ë°°ì¹˜ ë§ˆì´ê·¸ë ˆì´ì…˜
                migrated, failed = self.migrate_blocks(blocks)
                total_migrated += migrated
                total_failed += failed
                
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                self.migration_state['migrated_blocks'] = total_migrated
                self.migration_state['failed_blocks'] = total_failed
                self._save_migration_state()
                
                # ì§„í–‰ë¥  ì¶œë ¥
                progress = (total_migrated + total_failed) / analysis['blocks_to_migrate'] * 100
                logger.info(f"ğŸ“ˆ ì§„í–‰ë¥ : {progress:.1f}% ({total_migrated + total_failed:,}/{analysis['blocks_to_migrate']:,})")
                
                offset += batch_size
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
            self.migration_state['completed_at'] = datetime.now().isoformat()
            self._save_migration_state()
            
            logger.info(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
            logger.info(f"   ì„±ê³µ: {total_migrated:,}ê°œ")
            logger.info(f"   ì‹¤íŒ¨: {total_failed:,}ê°œ")
            
            return total_failed == 0
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def verify_migration(self) -> bool:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦"""
        try:
            logger.info("ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì¤‘...")
            
            # ìƒ˜í”Œ ë¸”ë¡ ê²€ì¦
            cursor = self.db_manager.connection.cursor()
            cursor.execute("""
                SELECT b.block_index, b.context, e.embedding_model, e.embedding_dim
                FROM blocks b
                LEFT JOIN block_embeddings e ON b.block_index = e.block_index
                WHERE e.embedding_model LIKE 'st_%'
                ORDER BY RANDOM()
                LIMIT 10
            """)
            
            sample_blocks = cursor.fetchall()
            
            if not sample_blocks:
                logger.warning("âš ï¸ ê²€ì¦í•  ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            # ê° ìƒ˜í”Œ ë¸”ë¡ ê²€ì¦
            for block_index, context, model_name, dim in sample_blocks:
                # ìƒˆ ì„ë² ë”© ìƒì„±
                expected_embedding = self.new_model.encode(context)
                
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì„ë² ë”© ì¡°íšŒ
                cursor.execute("SELECT embedding FROM block_embeddings WHERE block_index = ?", (block_index,))
                result = cursor.fetchone()
                
                if not result:
                    logger.error(f"âŒ ë¸”ë¡ {block_index}: ì„ë² ë”© ë°ì´í„° ì—†ìŒ")
                    return False
                
                stored_embedding = np.frombuffer(result[0], dtype=np.float32).tolist()
                
                # ì°¨ì› ê²€ì¦
                if len(stored_embedding) != len(expected_embedding):
                    logger.error(f"âŒ ë¸”ë¡ {block_index}: ì°¨ì› ë¶ˆì¼ì¹˜ ({len(stored_embedding)} vs {len(expected_embedding)})")
                    return False
                
                # ìœ ì‚¬ë„ ê²€ì¦ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
                similarity = self.new_model.similarity(stored_embedding, expected_embedding)
                if similarity < 0.99:  # 99% ì´ìƒ ìœ ì‚¬í•´ì•¼ í•¨
                    logger.error(f"âŒ ë¸”ë¡ {block_index}: ìœ ì‚¬ë„ ë¶ˆì¼ì¹˜ ({similarity:.4f})")
                    return False
            
            logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì„ë² ë”© ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ v2.0')
    parser.add_argument('--db-path', default='data/memory.db', help='ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ')
    parser.add_argument('--backup-path', help='ë°±ì—… ê²½ë¡œ')
    parser.add_argument('--batch-size', type=int, default=100, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--dry-run', action='store_true', help='ë“œë¼ì´ëŸ° ëª¨ë“œ')
    parser.add_argument('--verify-only', action='store_true', help='ê²€ì¦ë§Œ ìˆ˜í–‰')
    parser.add_argument('--rollback', action='store_true', help='ë¡¤ë°± ìˆ˜í–‰')
    parser.add_argument('--force', action='store_true', help='ê°•ì œ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬ì ì´ˆê¸°í™”
    migrator = EmbeddingMigrator(args.db_path, args.backup_path)
    
    if not migrator.initialize():
        logger.error("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return 1
    
    # ë¡¤ë°± ëª¨ë“œ
    if args.rollback:
        if not args.force:
            response = input("ì •ë§ë¡œ ë¡¤ë°±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if response.lower() != 'y':
                logger.info("ë¡¤ë°± ì·¨ì†Œë¨")
                return 0
        
        if migrator.rollback():
            logger.info("âœ… ë¡¤ë°± ì™„ë£Œ")
            return 0
        else:
            logger.error("âŒ ë¡¤ë°± ì‹¤íŒ¨")
            return 1
    
    # ê²€ì¦ ëª¨ë“œ
    if args.verify_only:
        if migrator.verify_migration():
            logger.info("âœ… ê²€ì¦ ì™„ë£Œ")
            return 0
        else:
            logger.error("âŒ ê²€ì¦ ì‹¤íŒ¨")
            return 1
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    if not args.force:
        analysis = migrator.analyze_migration_scope()
        if analysis.get('blocks_to_migrate', 0) > 0:
            response = input(f"ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ({analysis['blocks_to_migrate']:,}ê°œ ë¸”ë¡) (y/N): ")
            if response.lower() != 'y':
                logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì·¨ì†Œë¨")
                return 0
    
    if migrator.run_migration(args.batch_size, args.dry_run):
        if not args.dry_run:
            if migrator.verify_migration():
                logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ê²€ì¦ ì™„ë£Œ")
                return 0
            else:
                logger.error("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹¤íŒ¨")
                return 1
        else:
            logger.info("âœ… ë“œë¼ì´ëŸ° ì™„ë£Œ")
            return 0
    else:
        logger.error("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨")
        return 1


if __name__ == '__main__':
    sys.exit(main())

# Greeum v3.0.0 Architecture Design
## ì—°ìƒ ê¸°ë°˜ ì§€ëŠ¥í˜• ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ

---

## ğŸ—ï¸ **ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜**

### í•µì‹¬ ì„¤ê³„ ì›ì¹™
1. **ì—°ìƒ ìš°ì„ **: ë‹¨ìˆœ ë§¤ì¹­ì´ ì•„ë‹Œ ì—°ìƒ ë„¤íŠ¸ì›Œí¬
2. **LLM í˜‘ë ¥**: ì¶”ë¡ ì€ LLMì´, ë°ì´í„°ëŠ” Greeumì´
3. **ì ì§„ì  í™•ì¥**: MVPë¶€í„° ì‹œì‘, ë‹¨ê³„ì  ê¸°ëŠ¥ ì¶”ê°€
4. **v2 í˜¸í™˜ì„±**: ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë³‘í–‰ ìš´ì˜ ê°€ëŠ¥

---

## ğŸ“Š **ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ**

### 1. Core Tables

```sql
-- ë©”ëª¨ë¦¬ ë…¸ë“œ (ê¸°ë³¸ ë‹¨ìœ„)
CREATE TABLE memory_nodes (
    node_id INTEGER PRIMARY KEY AUTOINCREMENT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    content TEXT NOT NULL,
    
    -- êµ¬ì¡°í™”ëœ ì •ë³´ (ì„ íƒì )
    subject TEXT,           -- ì£¼ì²´
    action TEXT,            -- í–‰ë™
    object TEXT,            -- ê°ì²´
    
    -- ë©”íƒ€ë°ì´í„°
    importance REAL DEFAULT 0.5,
    access_count INTEGER DEFAULT 0,
    last_accessed TIMESTAMP,
    
    -- ë‹¤ì°¨ì› ì¸ë±ìŠ¤
    temporal_index INTEGER,  -- ì‹œê°„ì¶• ìœ„ì¹˜
    emotional_tone REAL,     -- -1(ë¶€ì •) ~ 1(ê¸ì •)
    context_hash TEXT,       -- ë§¥ë½ ì‹ë³„ì
    
    INDEX idx_temporal (temporal_index),
    INDEX idx_subject (subject),
    INDEX idx_context (context_hash)
);

-- ì—°ìƒ ì—°ê²° (ê°€ì¤‘ì¹˜ ê·¸ë˜í”„)
CREATE TABLE associations (
    assoc_id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_node INTEGER NOT NULL,
    target_node INTEGER NOT NULL,
    
    -- ì—°ê²° íƒ€ì…ê³¼ ê°•ë„
    assoc_type TEXT NOT NULL,  -- semantic, temporal, causal, subject, object
    strength REAL DEFAULT 0.5,  -- 0.0 ~ 1.0
    
    -- í™œì„±í™” ì •ë³´
    activation_count INTEGER DEFAULT 0,
    last_activated TIMESTAMP,
    
    -- í•™ìŠµ ì •ë³´
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by TEXT,  -- user, system, learned
    
    FOREIGN KEY (source_node) REFERENCES memory_nodes(node_id),
    FOREIGN KEY (target_node) REFERENCES memory_nodes(node_id),
    UNIQUE(source_node, target_node, assoc_type),
    INDEX idx_source (source_node),
    INDEX idx_target (target_node),
    INDEX idx_strength (strength DESC)
);

-- í™œì„±í™” ì´ë ¥ (ì„¸ì…˜ë³„ í™œì„±í™” íŒ¨í„´)
CREATE TABLE activation_history (
    activation_id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    node_id INTEGER NOT NULL,
    activation_level REAL NOT NULL,  -- 0.0 ~ 1.0
    activation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    trigger_node INTEGER,  -- í™œì„±í™”ë¥¼ ìœ ë°œí•œ ë…¸ë“œ
    
    FOREIGN KEY (node_id) REFERENCES memory_nodes(node_id),
    INDEX idx_session (session_id),
    INDEX idx_time (activation_time DESC)
);

-- ë§¥ë½ ì„¸ì…˜ (ëŒ€í™”/ì‘ì—… ë‹¨ìœ„)
CREATE TABLE context_sessions (
    session_id TEXT PRIMARY KEY,
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ended_at TIMESTAMP,
    
    -- ì„¸ì…˜ ë©”íƒ€ë°ì´í„°
    session_type TEXT,  -- conversation, task, exploration
    primary_topics TEXT,  -- JSON array of main topics
    total_activations INTEGER DEFAULT 0,
    
    -- ì„¸ì…˜ ìƒíƒœ
    active_nodes TEXT,  -- JSON array of currently active node IDs
    context_vector TEXT  -- JSON array of context weights
);
```

### 2. Indexing Tables

```sql
-- í‚¤ì›Œë“œ ì¸ë±ìŠ¤ (ë¹ ë¥¸ ì´ˆê¸° ê²€ìƒ‰)
CREATE TABLE keyword_index (
    keyword TEXT NOT NULL,
    node_id INTEGER NOT NULL,
    frequency INTEGER DEFAULT 1,
    
    PRIMARY KEY (keyword, node_id),
    FOREIGN KEY (node_id) REFERENCES memory_nodes(node_id)
);

-- ì‹œê°„ ìœˆë„ìš° ì¸ë±ìŠ¤ (ì‹œê°„ ê¸°ë°˜ ê²€ìƒ‰)
CREATE TABLE temporal_windows (
    window_id INTEGER PRIMARY KEY,
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP NOT NULL,
    node_count INTEGER DEFAULT 0,
    summary TEXT,
    
    INDEX idx_time_range (start_time, end_time)
);

-- í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤ (ì£¼ì œë³„ ê·¸ë£¹)
CREATE TABLE memory_clusters (
    cluster_id INTEGER PRIMARY KEY AUTOINCREMENT,
    cluster_name TEXT,
    centroid_node INTEGER,
    member_count INTEGER DEFAULT 0,
    
    FOREIGN KEY (centroid_node) REFERENCES memory_nodes(node_id)
);

CREATE TABLE cluster_members (
    cluster_id INTEGER NOT NULL,
    node_id INTEGER NOT NULL,
    distance_to_centroid REAL,
    
    PRIMARY KEY (cluster_id, node_id),
    FOREIGN KEY (cluster_id) REFERENCES memory_clusters(cluster_id),
    FOREIGN KEY (node_id) REFERENCES memory_nodes(node_id)
);
```

---

## ğŸ§  **í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì„¤ê³„**

### 1. AssociationNetwork (ì—°ìƒ ë„¤íŠ¸ì›Œí¬)

```python
class AssociationNetwork:
    """
    ë©”ëª¨ë¦¬ ë…¸ë“œ ê°„ ì—°ìƒ ê´€ê³„ë¥¼ ê´€ë¦¬í•˜ëŠ” í•µì‹¬ ì—”ì§„
    """
    
    def __init__(self, db_manager):
        self.db = db_manager
        self.cache = AssociationCache()  # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì—°ê²° ìºì‹±
        
    def create_association(self, source_id: int, target_id: int, 
                         assoc_type: str, strength: float = 0.5):
        """ë‘ ë…¸ë“œ ê°„ ì—°ìƒ ì—°ê²° ìƒì„±"""
        # ì¤‘ë³µ ì²´í¬
        if self.has_association(source_id, target_id, assoc_type):
            return self.strengthen_association(source_id, target_id, strength * 0.1)
        
        # ìƒˆ ì—°ê²° ìƒì„±
        self.db.execute("""
            INSERT INTO associations (source_node, target_node, assoc_type, strength)
            VALUES (?, ?, ?, ?)
        """, (source_id, target_id, assoc_type, strength))
        
        # ìºì‹œ ë¬´íš¨í™”
        self.cache.invalidate(source_id)
        
    def find_associations(self, node_id: int, max_depth: int = 2) -> Dict:
        """
        íŠ¹ì • ë…¸ë“œì—ì„œ ì‹œì‘í•˜ëŠ” ì—°ìƒ ë„¤íŠ¸ì›Œí¬ íƒìƒ‰
        BFS ë°©ì‹ìœ¼ë¡œ depthë§Œí¼ í™•ì¥
        """
        visited = set()
        network = {
            "center": node_id,
            "layers": []
        }
        
        current_layer = [node_id]
        
        for depth in range(max_depth):
            next_layer = []
            layer_associations = []
            
            for current_node in current_layer:
                if current_node in visited:
                    continue
                    
                visited.add(current_node)
                
                # í˜„ì¬ ë…¸ë“œì˜ ëª¨ë“  ì—°ê²° ì¡°íšŒ
                associations = self.db.query("""
                    SELECT target_node, assoc_type, strength
                    FROM associations
                    WHERE source_node = ?
                    ORDER BY strength DESC
                    LIMIT 10
                """, (current_node,))
                
                for assoc in associations:
                    if assoc['target_node'] not in visited:
                        next_layer.append(assoc['target_node'])
                        layer_associations.append({
                            "from": current_node,
                            "to": assoc['target_node'],
                            "type": assoc['assoc_type'],
                            "strength": assoc['strength']
                        })
            
            if layer_associations:
                network["layers"].append({
                    "depth": depth + 1,
                    "associations": layer_associations
                })
            
            current_layer = next_layer
            
        return network
    
    def strengthen_association(self, source_id: int, target_id: int, delta: float):
        """ì—°ê²° ê°•ë„ ì¦ê°€ (ì‚¬ìš©í• ìˆ˜ë¡ ê°•í•´ì§)"""
        self.db.execute("""
            UPDATE associations 
            SET strength = MIN(1.0, strength + ?),
                activation_count = activation_count + 1,
                last_activated = CURRENT_TIMESTAMP
            WHERE source_node = ? AND target_node = ?
        """, (delta, source_id, target_id))
    
    def decay_associations(self, decay_rate: float = 0.95):
        """ì‹œê°„ì— ë”°ë¥¸ ì—°ê²° ê°•ë„ ê°ì‡  (ë¯¸ì‚¬ìš© ì—°ê²° ì•½í™”)"""
        self.db.execute("""
            UPDATE associations
            SET strength = strength * ?
            WHERE last_activated < datetime('now', '-7 days')
        """, (decay_rate,))
```

### 2. SpreadingActivation (í™œì„±í™” í™•ì‚°)

```python
class SpreadingActivation:
    """
    í•˜ë‚˜ì˜ ê¸°ì–µì´ í™œì„±í™”ë˜ë©´ ì—°ê´€ëœ ê¸°ì–µë“¤ë„ í•¨ê»˜ í™œì„±í™”
    ì¸ê°„ì˜ ì—°ìƒ ì‘ìš©ì„ ëª¨ë°©
    """
    
    def __init__(self, network: AssociationNetwork):
        self.network = network
        self.activation_threshold = 0.3  # ìµœì†Œ í™œì„±í™” ìˆ˜ì¤€
        self.decay_factor = 0.7  # ê±°ë¦¬ì— ë”°ë¥¸ ê°ì‡ 
        
    def activate(self, trigger_nodes: List[int], session_id: str) -> Dict[int, float]:
        """
        íŠ¸ë¦¬ê±° ë…¸ë“œë“¤ë¡œë¶€í„° í™œì„±í™” í™•ì‚°
        
        Returns:
            {node_id: activation_level} í˜•íƒœì˜ í™œì„±í™” ë§µ
        """
        activation_map = {}
        
        # ì´ˆê¸° í™œì„±í™” (íŠ¸ë¦¬ê±° ë…¸ë“œë“¤ì€ 1.0)
        for node in trigger_nodes:
            activation_map[node] = 1.0
            self._record_activation(session_id, node, 1.0, None)
        
        # 3ë‹¨ê³„ê¹Œì§€ í™•ì‚°
        for depth in range(1, 4):
            new_activations = {}
            decay = self.decay_factor ** depth
            
            for active_node, activation_level in activation_map.items():
                if activation_level < self.activation_threshold:
                    continue
                
                # ì—°ê²°ëœ ë…¸ë“œë“¤ í™œì„±í™”
                associations = self.network.find_associations(active_node, max_depth=1)
                
                for layer in associations.get("layers", []):
                    for assoc in layer["associations"]:
                        target = assoc["to"]
                        
                        # ì—°ê²° ê°•ë„ì™€ ê±°ë¦¬ë¥¼ ê³ ë ¤í•œ í™œì„±í™” ìˆ˜ì¤€ ê³„ì‚°
                        propagated_activation = activation_level * assoc["strength"] * decay
                        
                        if target not in activation_map:
                            new_activations[target] = propagated_activation
                        else:
                            # ì—¬ëŸ¬ ê²½ë¡œë¡œ í™œì„±í™”ë˜ë©´ ìµœëŒ€ê°’ ì‚¬ìš©
                            new_activations[target] = max(
                                new_activations.get(target, 0),
                                propagated_activation
                            )
            
            # ìƒˆë¡œ í™œì„±í™”ëœ ë…¸ë“œë“¤ ê¸°ë¡
            for node, level in new_activations.items():
                if level >= self.activation_threshold:
                    activation_map[node] = level
                    self._record_activation(session_id, node, level, active_node)
        
        return activation_map
    
    def _record_activation(self, session_id: str, node_id: int, 
                          level: float, trigger: Optional[int]):
        """í™œì„±í™” ì´ë ¥ ê¸°ë¡"""
        self.network.db.execute("""
            INSERT INTO activation_history 
            (session_id, node_id, activation_level, trigger_node)
            VALUES (?, ?, ?, ?)
        """, (session_id, node_id, level, trigger))
```

### 3. ContextManager (ë§¥ë½ ê´€ë¦¬ì)

```python
class ContextManager:
    """
    ëŒ€í™”/ì‘ì—…ì˜ ë§¥ë½ì„ ì¶”ì í•˜ê³  ê´€ë ¨ ê¸°ì–µì„ ì§€ì†ì ìœ¼ë¡œ ì œê³µ
    """
    
    def __init__(self, network: AssociationNetwork, activation: SpreadingActivation):
        self.network = network
        self.activation = activation
        self.active_context = {}
        
    def start_session(self, session_type: str = "conversation") -> str:
        """ìƒˆ ë§¥ë½ ì„¸ì…˜ ì‹œì‘"""
        session_id = self._generate_session_id()
        
        self.network.db.execute("""
            INSERT INTO context_sessions (session_id, session_type)
            VALUES (?, ?)
        """, (session_id, session_type))
        
        self.active_context[session_id] = {
            "active_nodes": [],
            "context_vector": {},
            "turn_count": 0
        }
        
        return session_id
    
    def update_context(self, session_id: str, new_input: str) -> Dict:
        """
        ìƒˆ ì…ë ¥ì— ë”°ë¼ ë§¥ë½ ì—…ë°ì´íŠ¸ ë° ê´€ë ¨ ê¸°ì–µ ë°˜í™˜
        """
        context = self.active_context.get(session_id, {})
        
        # 1. ìƒˆ ì…ë ¥ì—ì„œ ê´€ë ¨ ë…¸ë“œ ê²€ìƒ‰
        relevant_nodes = self._find_relevant_nodes(new_input)
        
        # 2. í™œì„±í™” í™•ì‚°ìœ¼ë¡œ ì—°ê´€ ê¸°ì–µ ì°¾ê¸°
        activation_map = self.activation.activate(relevant_nodes, session_id)
        
        # 3. ê¸°ì¡´ í™œì„± ë…¸ë“œ ê°ì‡ 
        for node in context.get("active_nodes", []):
            if node not in activation_map:
                activation_map[node] = context["context_vector"].get(node, 0) * 0.7
        
        # 4. ë§¥ë½ ì—…ë°ì´íŠ¸
        context["active_nodes"] = list(activation_map.keys())
        context["context_vector"] = activation_map
        context["turn_count"] += 1
        
        # 5. ìƒìœ„ Nê°œ í™œì„±í™”ëœ ê¸°ì–µ ë°˜í™˜
        top_memories = self._get_top_memories(activation_map, limit=20)
        
        return {
            "direct_matches": relevant_nodes,
            "associated_memories": top_memories,
            "context_strength": self._calculate_context_coherence(activation_map)
        }
    
    def _find_relevant_nodes(self, text: str) -> List[int]:
        """í…ìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ ì´ˆê¸° ë…¸ë“œë“¤ ê²€ìƒ‰"""
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(text)
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë…¸ë“œ ê²€ìƒ‰
        nodes = []
        for keyword in keywords:
            results = self.network.db.query("""
                SELECT DISTINCT node_id 
                FROM keyword_index
                WHERE keyword = ?
                LIMIT 5
            """, (keyword,))
            nodes.extend([r['node_id'] for r in results])
        
        return list(set(nodes))
    
    def _get_top_memories(self, activation_map: Dict[int, float], 
                         limit: int = 20) -> List[Dict]:
        """í™œì„±í™” ìˆ˜ì¤€ì´ ë†’ì€ ìƒìœ„ Nê°œ ê¸°ì–µ ì¡°íšŒ"""
        sorted_nodes = sorted(
            activation_map.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:limit]
        
        memories = []
        for node_id, activation_level in sorted_nodes:
            memory = self.network.db.query_one("""
                SELECT content, subject, action, object, emotional_tone
                FROM memory_nodes
                WHERE node_id = ?
            """, (node_id,))
            
            if memory:
                memories.append({
                    "node_id": node_id,
                    "activation": activation_level,
                    "content": memory['content'],
                    "structure": {
                        "subject": memory['subject'],
                        "action": memory['action'],
                        "object": memory['object']
                    },
                    "emotion": memory['emotional_tone']
                })
        
        return memories
```

### 4. MemoryIndexer (ë‹¤ì°¨ì› ì¸ë±ì‹±)

```python
class MemoryIndexer:
    """
    ë©”ëª¨ë¦¬ë¥¼ ë‹¤ì–‘í•œ ì°¨ì›ìœ¼ë¡œ ì¸ë±ì‹±í•˜ì—¬ ë¹ ë¥¸ ì ‘ê·¼ ê°€ëŠ¥
    """
    
    def __init__(self, db_manager):
        self.db = db_manager
        
    def index_memory(self, node_id: int, content: str, metadata: Dict):
        """ìƒˆ ë©”ëª¨ë¦¬ ë…¸ë“œ ì¸ë±ì‹±"""
        
        # 1. í‚¤ì›Œë“œ ì¸ë±ì‹±
        keywords = self._extract_keywords(content)
        for keyword in keywords:
            self.db.execute("""
                INSERT OR REPLACE INTO keyword_index (keyword, node_id, frequency)
                VALUES (?, ?, COALESCE(
                    (SELECT frequency + 1 FROM keyword_index 
                     WHERE keyword = ? AND node_id = ?), 1))
            """, (keyword, node_id, keyword, node_id))
        
        # 2. ì‹œê°„ ìœˆë„ìš° í• ë‹¹
        timestamp = metadata.get('timestamp', datetime.now())
        window_id = self._get_or_create_time_window(timestamp)
        
        # 3. ê°ì • ì¸ë±ì‹±
        emotional_tone = self._analyze_emotion(content)
        
        # 4. êµ¬ì¡°ì  ìš”ì†Œ ì¶”ì¶œ
        structure = self._extract_structure(content)
        
        # ë…¸ë“œ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        self.db.execute("""
            UPDATE memory_nodes
            SET temporal_index = ?,
                emotional_tone = ?,
                subject = ?,
                action = ?,
                object = ?
            WHERE node_id = ?
        """, (window_id, emotional_tone, 
              structure.get('subject'),
              structure.get('action'),
              structure.get('object'),
              node_id))
    
    def search_by_dimension(self, dimension: str, value: Any, limit: int = 10):
        """íŠ¹ì • ì°¨ì›ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        
        if dimension == "temporal":
            # ì‹œê°„ ê¸°ë°˜ ê²€ìƒ‰
            return self.db.query("""
                SELECT * FROM memory_nodes
                WHERE temporal_index = ?
                ORDER BY created_at DESC
                LIMIT ?
            """, (value, limit))
            
        elif dimension == "emotional":
            # ê°ì • ê¸°ë°˜ ê²€ìƒ‰
            return self.db.query("""
                SELECT * FROM memory_nodes
                WHERE ABS(emotional_tone - ?) < 0.2
                ORDER BY ABS(emotional_tone - ?)
                LIMIT ?
            """, (value, value, limit))
            
        elif dimension == "subject":
            # ì£¼ì²´ ê¸°ë°˜ ê²€ìƒ‰
            return self.db.query("""
                SELECT * FROM memory_nodes
                WHERE subject = ?
                ORDER BY importance DESC
                LIMIT ?
            """, (value, limit))
```

---

## ğŸ”„ **í†µí•© ì‘ë™ í”Œë¡œìš°**

```python
class GreeumV3:
    """
    v3.0.0 ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    """
    
    def __init__(self):
        self.db = DatabaseManager()
        self.network = AssociationNetwork(self.db)
        self.activation = SpreadingActivation(self.network)
        self.context = ContextManager(self.network, self.activation)
        self.indexer = MemoryIndexer(self.db)
        
    def add_memory(self, content: str, metadata: Dict = None) -> int:
        """ìƒˆ ë©”ëª¨ë¦¬ ì¶”ê°€"""
        
        # 1. ë…¸ë“œ ìƒì„±
        node_id = self.db.execute("""
            INSERT INTO memory_nodes (content, importance)
            VALUES (?, ?)
        """, (content, metadata.get('importance', 0.5)))
        
        # 2. ì¸ë±ì‹±
        self.indexer.index_memory(node_id, content, metadata or {})
        
        # 3. ìë™ ì—°ìƒ ì—°ê²° ìƒì„±
        self._create_automatic_associations(node_id, content)
        
        return node_id
    
    def recall(self, query: str, session_id: str = None) -> Dict:
        """ì—°ìƒ ê¸°ë°˜ ê¸°ì–µ íšŒìƒ"""
        
        # ì„¸ì…˜ ê´€ë¦¬
        if not session_id:
            session_id = self.context.start_session()
        
        # ë§¥ë½ ì—…ë°ì´íŠ¸ ë° ì—°ìƒ í™œì„±í™”
        result = self.context.update_context(session_id, query)
        
        return {
            "session_id": session_id,
            "memories": result["associated_memories"],
            "context_coherence": result["context_strength"],
            "association_map": self._visualize_associations(result)
        }
    
    def _create_automatic_associations(self, node_id: int, content: str):
        """ìƒˆ ë©”ëª¨ë¦¬ì— ëŒ€í•œ ìë™ ì—°ìƒ ì—°ê²° ìƒì„±"""
        
        # ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ ì°¾ê¸°
        similar = self._find_similar_memories(content, limit=5)
        
        for similar_node, similarity in similar:
            if similarity > 0.7:
                self.network.create_association(
                    node_id, similar_node,
                    "semantic", similarity
                )
        
        # ì‹œê°„ì ìœ¼ë¡œ ê°€ê¹Œìš´ ë©”ëª¨ë¦¬ ì—°ê²°
        recent = self.db.query("""
            SELECT node_id FROM memory_nodes
            WHERE node_id != ?
            ORDER BY created_at DESC
            LIMIT 3
        """, (node_id,))
        
        for r in recent:
            self.network.create_association(
                node_id, r['node_id'],
                "temporal", 0.5
            )
```

---

## ğŸ“ˆ **ì„±ëŠ¥ ìµœì í™” ì „ëµ**

### 1. ìºì‹±
- ìì£¼ í™œì„±í™”ë˜ëŠ” ì—°ìƒ ê²½ë¡œ ìºì‹±
- ì„¸ì…˜ë³„ í™œì„± ë…¸ë“œ ë©”ëª¨ë¦¬ ìºì‹œ
- í‚¤ì›Œë“œ-ë…¸ë“œ ë§¤í•‘ ìºì‹œ

### 2. ì¸ë±ì‹±
- ë³µí•© ì¸ë±ìŠ¤ë¡œ ë‹¤ì°¨ì› ê²€ìƒ‰ ìµœì í™”
- ë¶€ë¶„ ì¸ë±ìŠ¤ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- ì •ê¸°ì  ì¸ë±ìŠ¤ ì¬êµ¬ì„±

### 3. ë°°ì¹˜ ì²˜ë¦¬
- ì—°ìƒ ì—°ê²° ë°°ì¹˜ ìƒì„±
- í™œì„±í™” ì´ë ¥ ë°°ì¹˜ ê¸°ë¡
- ê°ì‡  ì—°ì‚° ë°°ì¹˜ ì‹¤í–‰

---

## ğŸ¯ **êµ¬í˜„ ìš°ì„ ìˆœìœ„**

1. **Week 1-2**: ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ë° ë…¸ë“œ ê´€ë¦¬
2. **Week 3-4**: AssociationNetwork êµ¬í˜„
3. **Week 5-6**: SpreadingActivation ì•Œê³ ë¦¬ì¦˜
4. **Week 7-8**: ContextManager ë° í†µí•©
5. **Week 9-10**: ì„±ëŠ¥ ìµœì í™” ë° í…ŒìŠ¤íŠ¸

---

## ğŸ“Š **ì˜ˆìƒ ë©”íŠ¸ë¦­**

| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|-----------|
| ì—°ìƒ ì •í™•ë„ | 70% | ê´€ë ¨ ê¸°ì–µ ë¹„ìœ¨ |
| í™œì„±í™” ì†ë„ | <100ms | 3ë‹¨ê³„ í™•ì‚° ì‹œê°„ |
| ë§¥ë½ ìœ ì§€ | 10í„´ | ëŒ€í™” ì¼ê´€ì„± |
| ë©”ëª¨ë¦¬ í™œìš©ë¥  | 40% | ì„¸ì…˜ë‹¹ í™œì„±í™” ë¹„ìœ¨ |

ì´ êµ¬ì¡°ëŠ” ì§„ì •í•œ **ì—°ìƒ ê¸°ë°˜ ì§€ëŠ¥í˜• ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ**ì˜ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.
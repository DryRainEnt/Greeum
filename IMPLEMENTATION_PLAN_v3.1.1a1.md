# v3.1.1a1 êµ¬í˜„ ê³„íšì„œ

## ğŸ¯ ëª©í‘œ
**SimpleEmbeddingModel(ëœë¤)ì„ SentenceTransformer(ì˜ë¯¸)ë¡œ êµì²´**

## ğŸ“ êµ¬í˜„ ì‘ì—… ëª©ë¡

### Step 1: SentenceTransformerModel í´ë˜ìŠ¤ êµ¬í˜„
**íŒŒì¼**: `greeum/embedding_models.py`

```python
class SentenceTransformerModel(EmbeddingModel):
    """Sentence-Transformers ê¸°ë°˜ ì˜ë¯¸ì  ì„ë² ë”© ëª¨ë¸"""

    def __init__(self, model_name: str = None):
        """
        Args:
            model_name: ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: ë‹¤êµ­ì–´ ëª¨ë¸)
        """
        try:
            from sentence_transformers import SentenceTransformer
        except ImportError:
            raise ImportError(
                "sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "pip install sentence-transformers ë˜ëŠ” "
                "pip install greeum[full]ì„ ì‹¤í–‰í•˜ì„¸ìš”."
            )

        # ê¸°ë³¸ ëª¨ë¸: ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨)
        if model_name is None:
            model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'

        self.model = SentenceTransformer(model_name)
        self.model_name = model_name
        self.dimension = self.model.get_sentence_embedding_dimension()

    def encode(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ì  ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        embedding = self.model.encode(text, convert_to_numpy=True)
        return embedding.tolist()

    def batch_encode(self, texts: List[str]) -> List[List[float]]:
        """ë°°ì¹˜ ì¸ì½”ë”© (ì„±ëŠ¥ ìµœì í™”)"""
        embeddings = self.model.encode(texts, convert_to_numpy=True)
        return embeddings.tolist()

    def get_dimension(self) -> int:
        return self.dimension

    def get_model_name(self) -> str:
        return f"sentence-transformers/{self.model_name}"
```

### Step 2: ì´ˆê¸°í™” í•¨ìˆ˜ êµ¬í˜„
**íŒŒì¼**: `greeum/embedding_models.py` (ì¶”ê°€)

```python
def init_sentence_transformer(model_name: str = None, set_as_default: bool = True):
    """Sentence-Transformer ëª¨ë¸ ì´ˆê¸°í™” ë° ë“±ë¡"""
    try:
        model = SentenceTransformerModel(model_name)
        embedding_registry.register_model(
            "sentence-transformer",
            model,
            set_as_default=set_as_default
        )

        # ì°¨ì› í™•ì¸ (ê¸°ì¡´ 768ê³¼ í˜¸í™˜ì„±)
        if model.get_dimension() != 768:
            logger.warning(
                f"ëª¨ë¸ ì°¨ì› {model.get_dimension()}ì´ ê¸°ë³¸ 768ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. "
                "ê¸°ì¡´ ë°ì´í„°ì™€ í˜¸í™˜ì„± ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )

        return model
    except ImportError as e:
        logger.error(f"Sentence-Transformer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise
```

### Step 3: ìë™ ì´ˆê¸°í™” ë¡œì§
**íŒŒì¼**: `greeum/embedding_models.py` (ìˆ˜ì •)

```python
# ì „ì—­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
embedding_registry = EmbeddingRegistry()

# ìë™ ì´ˆê¸°í™”: sentence-transformers ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ simple
def _auto_init_best_model():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì„ ì˜ ëª¨ë¸ ìë™ ì´ˆê¸°í™”"""
    try:
        # 1ìˆœìœ„: Sentence-Transformers
        init_sentence_transformer()
        logger.info("SentenceTransformer ëª¨ë¸ ìë™ ì´ˆê¸°í™” ì„±ê³µ")
    except ImportError:
        # 2ìˆœìœ„: Simple (ê²½ê³  í‘œì‹œ)
        logger.warning(
            "âš ï¸ sentence-transformersê°€ ì—†ì–´ SimpleEmbeddingModel ì‚¬ìš© ì¤‘.\n"
            "ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\n"
            "pip install sentence-transformersë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
        )
        embedding_registry.register_model(
            "simple",
            SimpleEmbeddingModel(dimension=768),
            set_as_default=True
        )

# ëª¨ë“ˆ ë¡œë“œ ì‹œ ìë™ ì‹¤í–‰
_auto_init_best_model()
```

### Step 4: ëª¨ë¸ ì„ íƒ ì „ëµ

#### í›„ë³´ ëª¨ë¸ ë¹„êµ
| ëª¨ë¸ | ì°¨ì› | í•œêµ­ì–´ | í¬ê¸° | ì†ë„ | ì„ íƒ |
|------|------|--------|------|------|------|
| paraphrase-multilingual-MiniLM-L12-v2 | 384 | âœ… | 118MB | ë¹ ë¦„ | â­ |
| xlm-r-100langs-bert-base-nli-stsb-mean-tokens | 768 | âœ… | 1GB | ë³´í†µ | |
| distiluse-base-multilingual-cased-v2 | 512 | âœ… | 135MB | ë¹ ë¦„ | |

**ì„ íƒ: paraphrase-multilingual-MiniLM-L12-v2**
- ì´ìœ : í•œêµ­ì–´ ì§€ì›, ê²½ëŸ‰, ë¹ ë¥¸ ì†ë„
- ë¬¸ì œ: 384ì°¨ì› (ê¸°ì¡´ 768ê³¼ ë¶ˆì¼ì¹˜)
- í•´ê²°: ì°¨ì› ë³€í™˜ ë˜ëŠ” ì¬ì¸ë±ì‹±

### Step 5: ì°¨ì› í˜¸í™˜ì„± ì²˜ë¦¬

```python
class DimensionAdapter:
    """ì°¨ì› ë³€í™˜ ì–´ëŒ‘í„°"""

    @staticmethod
    def adapt_embedding(embedding: List[float], target_dim: int = 768) -> List[float]:
        current_dim = len(embedding)

        if current_dim == target_dim:
            return embedding
        elif current_dim < target_dim:
            # Padding with zeros
            return embedding + [0.0] * (target_dim - current_dim)
        else:
            # Truncation
            return embedding[:target_dim]
```

### Step 6: ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/migrate_embeddings.py
def migrate_to_semantic_embeddings(db_path: str):
    """ê¸°ì¡´ ëœë¤ ì„ë² ë”©ì„ ì˜ë¯¸ì  ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""

    # 1. ìƒˆ ëª¨ë¸ ì´ˆê¸°í™”
    from greeum.embedding_models import init_sentence_transformer
    model = init_sentence_transformer()

    # 2. ëª¨ë“  ë¸”ë¡ ì¬ì¸ë±ì‹±
    db = DatabaseManager(db_path)
    blocks = db.get_all_blocks()

    for block in blocks:
        # ìƒˆ ì„ë² ë”© ìƒì„±
        new_embedding = model.encode(block['context'])

        # DB ì—…ë°ì´íŠ¸
        db.update_embedding(
            block['block_index'],
            new_embedding,
            model_name=model.get_model_name()
        )

    print(f"âœ… {len(blocks)}ê°œ ë¸”ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
```

### Step 7: í…ŒìŠ¤íŠ¸ ê³„íš

#### 7.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
def test_semantic_similarity():
    """ì˜ë¯¸ì  ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸"""
    model = SentenceTransformerModel()

    # ìœ ì‚¬í•œ í…ìŠ¤íŠ¸
    e1 = model.encode("íŒŒì´ì¬ìœ¼ë¡œ ì›¹ ê°œë°œí•˜ê¸°")
    e2 = model.encode("Python ì›¹ í”„ë¡œê·¸ë˜ë°")
    sim = cosine_similarity(e1, e2)
    assert sim > 0.6, f"ìœ ì‚¬ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë„ˆë¬´ ë‚®ìŒ: {sim}"

    # ë‹¤ë¥¸ í…ìŠ¤íŠ¸
    e3 = model.encode("ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë²•")
    sim2 = cosine_similarity(e1, e3)
    assert sim2 < 0.3, f"ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë„ˆë¬´ ë†’ìŒ: {sim2}"
```

#### 7.2 í†µí•© í…ŒìŠ¤íŠ¸
```python
def test_slot_allocation_with_semantic():
    """ì˜ë¯¸ ê¸°ë°˜ ìŠ¬ë¡¯ í• ë‹¹ í…ŒìŠ¤íŠ¸"""
    # A-B-C íŒ¨í„´ í…ŒìŠ¤íŠ¸
    # í”„ë¡œê·¸ë˜ë° ì»¨í…ìŠ¤íŠ¸ë“¤ì´ ê°™ì€ ìŠ¬ë¡¯ì—
    # ìš”ë¦¬ ì»¨í…ìŠ¤íŠ¸ëŠ” ë‹¤ë¥¸ ìŠ¬ë¡¯ì—
```

### Step 8: ì˜ì¡´ì„± ì—…ë°ì´íŠ¸

**pyproject.toml**:
```toml
[project.optional-dependencies]
semantic = ["sentence-transformers>=2.2.0"]
full = [
    "sentence-transformers>=2.2.0",  # í•„ìˆ˜ë¡œ ë³€ê²½
    "faiss-cpu>=1.7.4",
    # ...
]
```

## ğŸ“… ì¼ì •

| ì‘ì—… | ì˜ˆìƒ ì‹œê°„ | ìš°ì„ ìˆœìœ„ |
|------|-----------|----------|
| Step 1-2: í´ë˜ìŠ¤ êµ¬í˜„ | 2ì‹œê°„ | ğŸ”´ ìµœìƒ |
| Step 3: ìë™ ì´ˆê¸°í™” | 1ì‹œê°„ | ğŸ”´ ìµœìƒ |
| Step 4-5: ì°¨ì› ì²˜ë¦¬ | 2ì‹œê°„ | ğŸŸ¡ ë†’ìŒ |
| Step 6: ë§ˆì´ê·¸ë ˆì´ì…˜ | 3ì‹œê°„ | ğŸŸ¡ ë†’ìŒ |
| Step 7: í…ŒìŠ¤íŠ¸ | 2ì‹œê°„ | ğŸŸ¢ ë³´í†µ |
| Step 8: ë¬¸ì„œí™” | 1ì‹œê°„ | ğŸŸ¢ ë³´í†µ |

**ì´ ì˜ˆìƒ: 11ì‹œê°„**

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **í•˜ìœ„ í˜¸í™˜ì„±**: SimpleEmbeddingModel ìœ ì§€ (fallbackìš©)
2. **ì„±ëŠ¥**: ì²« ë¡œë“œ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (118MB)
3. **ë©”ëª¨ë¦¬**: ëª¨ë¸ ë¡œë“œ ì‹œ ~500MB RAM ì‚¬ìš©
4. **ì°¨ì›**: 384 vs 768 ë¶ˆì¼ì¹˜ ì²˜ë¦¬ í•„ìš”

## âœ… ì™„ë£Œ ê¸°ì¤€

- [ ] ìœ ì‚¬ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ > 0.5
- [ ] ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ < 0.3
- [ ] ìŠ¬ë¡¯ í• ë‹¹ ì •í™•ë„ > 80%
- [ ] ê¸°ì¡´ DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ
- [ ] CI/CD í†µê³¼

---

**ì‘ì„±ì¼**: 2024-12-16
**ë²„ì „**: v3.1.1a1
**ìƒíƒœ**: êµ¬í˜„ ëŒ€ê¸°